\chapter{Plugin system}
\vspace{-10mm}

Within the framework of cooperation between FNSPE faculty and IKEM, a

 few of FNSPE students are working on image segmentation algorithms of MRI images. Therefore, the idea to import these algorithms into Dicom-Presenter has been raised. The best idea was to design a plugin system for importing segmentation algorithms.
Plugin in computer sciences is an optional addition to some applications. It is not usually distributed with the application itself, but can be added by the user according to their needs. An example of a plugin can be an additional python script to Gimp program which allows user to apply 'sepia effect' on their photos. According to the mentioned example, plugins can be written in another language than the application itself, they obtain some new functionality to application.


All segmentation algorithms developed at FNSPE were written in C language due to its performance. Plugins in C language are compiled to a Dynamic-Link libraries and run-time loaded. A theory of C++ libraries and description of run-time loading libraries can be found in Section \ref{library}.

\section{Image Segmentation Algorithms Developed at FNSPE Faculty}
There are various different approaches to perform image segmentation examined on FNSPE faculty. Two algorithms were converted to be usable in Dicom-Presenter. The first one is based on Graph Theory \cite{loucky}, the second one is based on Level-Set Methods \cite{macaradek}.

\subsection{Image Segmentation Based on Graph Theory}
The algorithm is based on Minimum Cut problem in Graph Theory. Therefore, a graph based on the image is constructed. The edges of the graph are oriented and weighted. Then the Ford-Fulkerson algorithm is used to find the minimal cut, which describes the boundary of the segmented area.

There are two basic ideas of how to find the boundary of the segmented area\cite{loucky}:
\begin{itemize}
\item It is possible to search for the pairs of pixels, with the highest difference in their intensities.
\item If some pixels inside the segmented area are known, it is possible to search for pixels with a similar intensity.
\end{itemize}
The algorithm described in the following text comprehends both ideas.

Based on preceding description, the algorithm needs a set of pixels, which are located inside the segmented area. Let's denote the set $S$ (seed). Besides, a set of pixels outside the area must be given, it is denoted $O$ (outside)\cite{loucky}.

\subsubsection{Creating the Graph based on the Segmented Image}
Each pixels of the initial image is considered as a vertex of the graph. Two more vertices are added: source and sink - denoted $s$ and $k$.

Edges of the graph can be divided into three groups. The first group of edges connects each pixel of the graph with its closest four neighbors (denoted $E_{G}$). The second group of edges connects all vertices from $V - O$ with the source $s$ (denoted $E_{s}$). The last group connects all vertices from $V - S$ with the sink $a$ (denoted $E_{k}$).

\subsubsection{Setting the Edge Weights}
The next step of the algorithm is to set appropriate weights to the graph edges. Finding the weights is based on the idea, that all the pixels in the segmented area should have similar intensity. 

The process of finding the weights (throughput) of $E_{s}$ vertices is following\cite{loucky}:
\begin{itemize}
\item The edges connecting pixels from $S$ with the source $s$ have the highest weight.
\item The edges between the source $s$ and vertices from $V - O - S$ have that high weight as much is their intensity similar pixels from from $S$.
\end{itemize}
The weights of edges from $E_{k}$ are found similarly. This leads to the fact, that there will be a high flow from source to vertices inside of the segmented area, and also there will be a high flow from vertices outside of the area to the sink.

Finding the weights of edges from $E_{G}$ is based on the idea, that the boundary will be between the pairs of pixels with the greatest difference in their intensity. If the weights of the edges between those pairs of pixels will be set low, then the boundary can be found as minimum cut of the graph.

Therefore, the weight of the edge between pixels $p_{1}$ and $p_{2}$ is set as $D - \left(I_{p_{1}} - I_{p_{2}} \right)$ where $I_{p_{1}}$ is the intensity of the first pixel and $D = I_{max} - I_{min}$ is the difference between the lowest and the highest intensity on the picture\cite{loucky}.

\begin{figure}[!H]
 	\caption{The construction of a graph based on the segmented image. There is the segmented image of the first figure, S and O are a seed and an output. \label{fig:grafy}}
	\begin{center}
	\includegraphics[width=0.7\textwidth]{Text/IMG/grafy.jpg}
	\end{center}
\end{figure}

\subsection{Algorithm based on Level-set Method}
The algorithm performs expanding a closed curve inside the segmented area. The curve $\Gamma$ in time $t$ is described by function $u(x,y,t)$:

\begin{equation}
\label{lvsfunction}
\Gamma(t) = \{(x, y)|\, u(x,y,t) = 0 \}
\end{equation}

The function $\varphi(x,y,t)$ is called Level-set Function and is defined by a partial differential equation, called Level-set Equation. The members and initial values of the equation describe the function $u$ and therefore describe the behavior of the curve $\Gamma(t)$.

The exact form of the Level-set Equation used in the algorithm is:

\begin{center}
\includegraphics{Text/IMG/maca.png}
\end{center}
where $g^{0}$ is a function defined by the original image after edge detection. $D$ is called diffusion term, $A$ is called advection term and $S$ is called force term\cite{macaradek}.

\begin{comment}
The algorithm performs expanding a closed curve inside the segmented area. 

The idea of the algorithm is, that the time evolution of the curve can be described by a two-dimensional real function $\varphi:RxR->R$

Let $\Gamma$ is a curve. Let $\Gamma$ is expanding in each its point \emph{in the normal direction} with speed $v$. Then a function $\varphi$ fulfilling a condition:

\begin{equation}
\label{lvsfunction}
\frac{\partial\varphi}{\partial t} = v|\nabla \varphi|
\end{equation}

describes a time evolution of $\Gamma$ with:

\[
\Gamma(t) = \{(x, y)|\, \varphi(x, y) = c_{t} \}
\] 

The condition \ref{lvsfunction} is called Level-set equation. The function $\varphi$ fulfilling the condition is called Level-set function.

\begin{figure}[!H]
 	\caption{An evolution of two curves using Level-set function. The Level-set function is highlighted with a red color. \label{fig:levelsetgraf}}
	\begin{center}
	\includegraphics[width=0.55\textwidth]{Text/IMG/Level_set_method.jpg}
	\end{center}
\end{figure}

The above described curve $\Gamma(t)$ will expand in the normal direction. The goal is to stop expanding the curve at the area boundary. To do so a next member is added to the equation \ref{lvsfunction}. The member should act against the expansion on the area boundary.

A result of edge detection of the segmented image defines a two-dimensional function. The force-member of the equation is defined as negative gradient of the function.

\begin{equation}
\label{lvsfunctionwithforce}
\frac{\partial\varphi}{\partial t} = v|\nabla \varphi| - F
\end{equation}
\end{comment}

\subsection{Implementation of Image Segmentation Algorithms}
Both algorithms were implemented as C++ binary applications. The input of both algorithms is a set of two files - a segmented image and a file describing initial values.

The graph-based algorithm needs an image file with highlighted seeds and sinks - pixels inside the area and outside the area. The pixels inside/outside are highlighted with special color, the rest is black.

Since the second algorithm was implemented together with its own user interface written in Matlab, the algorithm needs a text file with a vector describing the initial condition. The vector has a length of $w \cdot h$, where $w$, $h$ are image width, height. Therefore, each number in the vector represents a pixel in the image. If the number is -1 the pixel is outside the segmented are, if the value is 1 the pixel is inside the segmented area. The C++ binary itself finds a boundary of the designed area.

The idea when designing the plugin system was, that user will be able to draw the initial part of the segmented area inside the original image. It is more similar to the first option of passing the initial values - passing them as an image. This option was implemented in Dicom-Presenter. The input of the second algorithm can be easily transformed to this option.

\section{Plugins System Requirements}
One of the main ideas when developing the plugin system for Dicom-Presenter was, that the system should be flexible enough, that any new image segmentation algorithm developed on FNSPE should be easily convertible to Dicom-Presenter. The first thing was to generalize what the libraries will need as an input and output. All three libraries made by FNSPE students required an image with designated segmentable area together with computational parameters as an input. The most reasonable way to insert computation parameters is to generate a GUI interface including any required input elements. This chapter discusses plugins GUI construction done at the application runtime and its connection to the loaded plugin library. A plugin interface was considered to be as simple as possible - a key idea was to require a minimum of source code modifications in existing image segmentation libraries.

\section{Generating Plugins GUI}

Dicom-Presenter's graphic user interface is built with use of Qt framework. Objects of Qt library classes represent application control elements. The objects can be created and displayed at a runtime according to plugin needs. An important question is which way to choose for plugin GUI description.

Qt library offers its own format of GUI description. There is a tool in Qt SDK\footnote{Qt Software Development Kit is a package for Qt based applications development. SDK includes library files together with a native development IDE.}, which offers an interactive GUI creation. It produces a XML file which describes the GUI. A strong argument for using this solution is that Qt library offers native tools for processing generated GUI description files.

Another possible way is to declare own language for GUI description. Firstly, it was implemented easily: Lines in a description file corresponded to GUI elements. First word of a line determined a type of an element. Other words on the line described element's properties such as default value, minimum and maximum value or matching function in a library. The second step was a transformation to XML standards. The result was similar to the preceding option but strict in syntax and naming. 

At first look, the first solution seems more reasonable. No new language is declared, though existing Qt library standard is used. Unfortunately, the Qt library syntax was primarily supposed to be generated by automated tool. The XML code is too complicated to be written manually - there are too many required phrases in the code. Moreover, GUI elements are described by class-names from Qt library - therefore, it is needed to know the Qt library to be able to write a description manually. The only option would be to generate GUI description by the Qt interactive tool. However, it is a complex tool, aimed for creating extensive GUI layouts for large applications. Image segmentation plugins require only a few control elements (input fields and buttons). It seems more accessible for a programmer to follow a few rules declared in GUI description language created for Dicom-Presenter instead of following the extensive number of rules attached to Qt GUI description language.

\subsection{Dicom-Presenter GUI Description Language}

The GUI description should determine types of control elements and their layout in interface window. The language for Dicom-Presenter GUI description is supposed to be simple. For every numeric input field it is needed to know: a required variable type (integer or float), the minimal and maximal possible value, the default value, a parameter description. Passing char parameters was realized by a combobox element - all possible values are listed in a dropdown menu.

A numeric field is declared by a string:

\clist{<numinput type="..." min="..." max="..." default="..." name="..."/>}

Where \clist{type} determines a C/C++ type (integer of double), \clist{min}, \clist{max}, \clist{default} determine minimum, maximum and default value and \clist{name} determines a parameter description.

A combobox can be declared in a similar way like in (X)HTML:

\noindent \indent \clist{<combobox type="..." name="...">}\\
\indent \indent \clist{<option value="..." name="..."/>}\\
\indent \indent \clist{<option value="..." name="..."/>}\\
\indent \clist{</combobox>}

Where \clist{type} determines a variable type passed to a library. \clist{name} in \clist{combobox} tag is a text description of property. The \clist{name} property in \clist{option} tag is a text description of a \clist{value} which is passed to a library.

An example GUI description file can be seen in Table \ref{tab:exampledescription}. The process of parsing a description file is illustrated on Listing \ref{parsingdescription} - the code refers to parsing information about a numeric input. Notable is the use of \clist{dymanic\_cast} operator, which allows unification of two different pointers, if the classes inherit the same parent.

\lstset{numbers=none,frame=none}

\begin{table}[ht]
	\caption{An example of a Dicom-Presenter plugin's GUI and its description.\label{tab:exampledescription}}
	\begin{tabular}{|m{\textwidth}|}
	\hline
\begin{lstlisting}[language=xml,morekeywords={zzz,ADD_EXECUTABLE,add_custom_command,add_library,target_link_libraries,OUTPUT,COMMAND,xxx})]
<xml>
  <numinput type="int" min="0" max="10" name="Lambda" function="lmbd"/>
  <numinput type="int" min="0" max="20" name="Sigma" function="sgm"/>
  <combobox type="char" name="Algorithm" function="algorithm">
    <option value="a" name="Modified algorithm"/>
    <option value="p" name="Original algorithm"/>
  </combobox>
  <button function="main" name="Run"/>
</xml>
\end{lstlisting}
		\\
		  \hline		
		  \noalign{\smallskip}
			\includegraphics[width=\textwidth]{Text/IMG/Plugins.png}
		\\
		\hline
		\end{tabular}
\end{table}%

\lstset{numbers=left,frame=single,}

\begin{lstlisting}[caption={Parsing data from a description file - integer input.}, language=C++,label=parsingdescription,morekeywords={zzz,ADD_EXECUTABLE,add_custom_command,add_library,target_link_libraries,OUTPUT,COMMAND,xxx})]
if (type=="int"||type=="double"){
	if (tag=="numinput") {
		QSpinBox *spinbox = new QSpinBox();
		...
		ControlerTable[i]=dynamic_cast<QWidget*>(spinbox); 
		Layout->addWidget(spinbox,1,y);
	}	
	if (tag=="combobox"){
		QComboBox *combobox = new QComboBox();
		if (e.hasChildNodes()){
			QDomNodeList childs=e.childNodes();
			for (int k=0; k<childs.count(); k++){
				QDomNode n = childs.at(k);
				QDomElement el = n.toElement();
				combobox->addItem(element.attribute("name"),element.attribute("value"));
			}					
		}
		ControlerTable[i]=dynamic_cast<QWidget*>(combobox); 
		Layout->addWidget(combobox,1,y);
		...
	}
	...	
}
\end{lstlisting}




%\subsection{Implementation of user interaction}



\section{Dynamically Loading Plugin Functions}

Dicom-Presenter's image segmentation algorithms use individual parameters. Therefore, each main computational function in each plugin needs individual number and types of parameters. A C/C++ function located in dynamically loaded library is run through a function pointer as seen on Listing \ref{sec:runtimeloading}. This pointer must have a fixed number and fixed types of parameters given at compilation. Thus, it is not possible to call various functions with various sets of parameters from a dynamically loaded library. It is only possible to run only a finite number of types of functions according to a set of given parameters. There were several solutions concerning how to make the Dicom-Presenter's plugin system variable enough to load and run previously unknown functions:

\begin{enumerate}
\item It is possible to pre-define a sufficient number of function pointer types at a compilation time. Then, each Dicom-Presenter plugin must have an input function of a predefined type.
\item Another solution is based on the fact that a function pointer can have more parameters than targeted function. For example, a function pointer having five integer parameters can point to a function receiving only three integer parameters - the last two given parameters will be ignored. Therefore it would be possible to define function pointers with excessive number of float, integer and char parameters. A function pointer would be assigned to a function to fit the first couple of parameters and to ignore the rest.
\item Another applicable way is to allow only one-parameter requiring functions to be present in a plugin. If the algorithm required more parameters, then appropriate functions settings these parameters would be run. Parameters can be saved as global variables to be accessible by main computational function. This solution has a significant advantage: It is possible to call the parameter setting functions simultaneously to user manipulating with relevant GUI elements. Then, an instant feedback from the library could be present (checking for incompatible values). This solution was implemented but it seemed too restrictive for library design. 
\item Next option is inspired by passing command line arguments to a standard C/C++ application. C/C++ Main Function receives a pointer to an array of all arguments. As in this case a plugin library function can receive three pointers to three array types: pointer to int, pointer to double and pointer to char. The arrays can be of any length.
\item Last option is to pass all parameters in a string. This option requires the plugin library to parse strings of some given format. 
\end{enumerate}

At first the third option was used in implementation. Function setting algorithm parameters were called while setting parameters in GUI. But there were no real benefits of library response while setting GUI parameters. More than that, the rules for plugins were too restrictive. 

Another reasonable option was nr. 5 - passing parameters in a string. The advantage is a flexibility of the system. On the other hand, image segmentation libraries will predominantly require numeric parameters. So, two conversions between numbers and strings would be needed.

Therefore, the final version of plugin API was implemented using option 4. The main function of a library receives pointers to three arrays where all parameters are saved. An illustration of the source code of this solution is on Listing \ref{parameters}.

\begin{lstlisting}[caption={A process of passing parameters to the main computational function of a library.}, language=C++,label=parameters,morekeywords={zzz,ADD_EXECUTABLE,add_custom_command,add_library,target_link_libraries,OUTPUT,COMMAND,xxx})]
typedef bool mainFunction(int*,char*,double*);
int *argi;
char *argc;
double *argd;
...
argi[0]=10;
argi[1]=20;
....
ProcessAdress = GetProcAddress("main");
mainFunction* func=(mainFunction*)ProcessAdress;
func(argi,argc,argd);
\end{lstlisting}

\section{User interaction in Image Segmentation plugins}
As previously mentioned, FNSPE image segmentation algorithms require computational parameters and an input image with designated area to be segmented. The segmentable area is defined by an initial curve. The entire initial curve has to be placed inside the segmentable area. The curve is then used as a set of initial values for algorithm. Mostly, the curve is iteratively expanded until it traces the area border. Then, the expanded curve fully defines the segmented area.

The initial curve needs to be defined by the user somehow. The most user-friendly way would be to allow the user to paint the initial curve right inside the segmented image using a pointing device (computer mouse, touchscreen, etc.) Qt library offers extensive possibilities to perform free-hand painting into an image.

\red{popsat vstup u kuby a u radka}
\red{napsat, ze se snimek da poslat do dicom-presenteru}

\subsection{Implementation of User Interaction}

Any mouse-control task in a computer application is mostly implemented according to the following schema: mouse movements are tracked by the application and redirected to a proper class, the actual mouse pointer position is obtained, an action based on the actual movement is performed and mouse movements are tracked again. The process is illustrated on Listing \ref{mousetrack}.

\begin{lstlisting}[label=mousetrack,caption={A solution of user input in Plugins API.},escapeinside={@}{@}]
iDrawLabel = new drawLabel();
iDrawLabel->setMouseTracking(true);
...
void drawLabel::mousePressEvent(QMouseEvent* event){
	if (event->button()==Qt::LeftButton) pressedButton = leftButton;
	if (event->button()==Qt::RightButton) pressedButton = rightButton;
}
void drawLabel::mouseMoveEvent(QMouseEvent* event){
	if (pressedButton==noButton) return;
	int x = event->x();
	int y = event->y();
	if (pressedButton==leftButton){
		QPainter painter((QPaintDevice*)pixmap());
		painter.setPen(QPen(Qt::white, 5, Qt::SolidLine, Qt::RoundCap,Qt::RoundJoin));
		painter.drawEllipse (x,y,5,5);
	}
	update();
}
void drawLabel::mouseReleaseEvent(QMouseEvent* event){
	pressedButton = noButton;
}
\end{lstlisting}

There are three functions related to mouse actions in the example \ref{mousetrack}: \clist{mousePressEvent}, \clist{mouseMoveEvent}, \clist{mouseReleaseEvent}. All the three functions are originally defined in Qt library and can be overloaded the demonstrated way. Qt framework ensures event-based calling of these overloaded functions. \clist{mousePressEvent} and \clist{mouseReleaseEvent} functions are called to avoid performing in \clist{mouseMoveEvent} action if no mouse-button is pressed. In fact, the \clist{QMouseEvent} object includes information about pressed buttons, therefore \clist{mousePressEvent} and \clist{mouseReleaseEvent} function calls could be eliminated. But it is a unique feature of Qt library; therefore, this implementation is more frequent.